---
title: 'I Am a Careless Person and AI Is Smarter'
subtitle: 'A Self Fulfilling Prophecy'
date: '2023-06-17'
slug: [ai-self-fulfilling-prophecy]
categories: [AI, Machine Learning, LLMs, Large Language Models]
tags: [AI, Machine Learning, LLMs, Large Language Models]

---

<blockquote>

*“I am a careless person,”* he said “AI will help me write better feedback.”.

*“Isn’t it better to try to be thoughful and think before writing?”* I said.

*“But AI can be my teacher. AI is much smarter”* he said with absolute certainty.

*“This could be his self fulfilling prophecy!”* I thought and shrugged, ending the conversation. ¯\\_(ツ)_/¯.
</blockquote>


# The "All You Need is AI" Mindset!

The previous lines were part of a conversation during a hackathon presentation I recently attended. As expected, Large Language Models(LLMs) were present in most of the projects in different ways. One of the team pitches was about **a tool for writing and getting feedback at workplaces**. The tool was claimed to address problems like:
- Employees laziness to write feedback *(whether in company surveys or annual appraisal /360 cycle)*.
- The difficulty of writing constructive feedback *(relevant, objective, not mean, etc.)*.
- The effort to summarize comments by managers.
- The effort to come up with action points based on feedback.

And because LLMs are claimed to be the solution for almost everything, *as many people currently promote*, the first choice for the team was to create a tool to help solve these problems. The presented features included:

- **Rewriting draft comments in a certain style**. One can write mean or ridiculous thoughts about a teammate and ask the tool to rewrite it in a certain tone.

- **Summarizing comments and coming up with action points**. A manager can just give the tool a bunch of comments and get action points with related links to share.

- And other features....

In principle, I am not against creating new tools or using the latest technology to solve problems. After all I am a Machine Learning (ML) Practitioner and I build ML-based systems. I am just against pitching new tools without showing a good understanding of the underlying problems, the social aspects and the human experience. In addition, I could always smell what [@Meredith Broussard](https://twitter.com/merbroussard) calls **"Technochauvinism"** referring to ***"The belief that technology is always the solution"***. And on this day, I saw many missing points that I wanted to reflect on!

# So What Was Missing Here?

After the presentation, I raised my hand saying that I would like to share some thoughts for reflection. I asked the presenter, some of the following questions:

- **Do you think the problem with writing feedback is the tool?**

- **Don’t you think that people sometimes stop writing feedback because they don’t see action from the organization?**. Anyone who worked at a big organization knows that some rituals like gathering feedback doesn’t necessarily result in a change. Some people even face retaliation for speaking up and highlighting issues.

- **If you are writing your thoughts, giving it to a tool, then reviewing the converted version. What about using this time to refine your thoughts and try to communicate what you really want to say in a proper way?**

- **What if managers rely on action points coming from irrelevant comments because they didn’t take the time to understand the context around their team dynamics and individual performance?.** They’d cross out this task from their list without really helping their team members. It could even end up in a frustrating experience if they just pass the output from the tool.

A comment following my questions came from an executive who looked at me and said something like **“As a manager I judge with my own bias. But I see a potential in AI to give me another lens to see things beyond my bias”!**  I shrugged, signaling that I had other views but I didn’t respond in order to give others the chance to ask questions.

# How Beliefs Shape Reality!

After all the presentations, a colleague approached me and jokingly said ***"You have strong opinions against AI!"***. I said, ***"No, I just have strong opinions about the used terms and conveyed beliefs while talking about AI"***. For instance I expected some valid arguments about the benefits of features like summarization, highlighting patterns, or finding vocabulary. Instead I was struck by the strong conviction about AI superiority.

- If a manager believes that AI is definitely capable of helping him see through his biases, he'll stop trying to improve and be objective while reading or writing feedback.

- If an adult holds a strong belief that he is *“a careless person”* who needs AI as a teacher because *“AI is definitely smarter”*,  he will act irresponsibly. He will say anything at work and social life, while waiting for external agents to rectify his actions and correct his words. 

In fact, it's the person's choice to decide whether they want to be like a thoughtless kid relying on gown ups to correct them, or a thoughtful grown up who thinks before acting. If they pick the first option, maybe they might degarde and be less smarter than an AI *(if intelligence could be defined and measured in the first place)*. **But then it will be their own self fulfilling prophecy!**

